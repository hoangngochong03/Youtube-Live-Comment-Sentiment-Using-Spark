{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386b0790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import RandomForestClassifier,LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.sql.functions import lower, col,regexp_replace,rand\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, IntegerType\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, HashingTF, IDF,Word2Vec\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe8166",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "os.environ[\"PYTHONPATH\"] = \"./sparkenv/Lib/site-packages\"  # replace path with your python env\n",
    "\n",
    "scala_version = '2.12'  # Scala version\n",
    "spark_version = '3.5.3' # Spark version\n",
    "\n",
    "packages = [\n",
    "    f'org.apache.spark:spark-sql-kafka-0-10_{scala_version}:{spark_version}',\n",
    "    'org.apache.kafka:kafka-clients:3.6.0'  # Kafka version\n",
    "]\n",
    "\n",
    "PYTHON_EXECUTABLE = \"//sparkenv/Scripts/python.exe\"# replace path with your python env\n",
    "# Replace path file that install in your folder\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Sentiment-Model\") \\\n",
    "    .config(\"spark.jars.packages\", \",\".join(packages)) \\\n",
    "    .config(\"spark.pyspark.python\", PYTHON_EXECUTABLE) \\\n",
    "    .config(\"spark.pyspark.driver.python\", PYTHON_EXECUTABLE) \\\n",
    "    .config(\"spark.executorEnv.PYTHONPATH\", PYTHON_EXECUTABLE) \\\n",
    "    .config(\"spark.executorEnv.PYSPARK_PYTHON\", PYTHON_EXECUTABLE) \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"./spark-3.5.3-bin-hadoop3/jars\") \\\n",
    "    .config(\"spark.executor.extraClassPath\", \"./spark-3.5.3-bin-hadoop3/jars\") \\\n",
    "    .config(\"spark.local.dir\", \"C:/sparktmp\") \\\n",
    "    .config(\"spark.hadoop.io.native.lib\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa8b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for training and testing\n",
    "train = spark.read.csv(r\".\\data\\vihsd\\train.csv\", header=True, inferSchema=True)\n",
    "test =spark.read.csv(r\".\\data\\vihsd\\test.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2528d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020012c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling for the major label in data to handle imbalance data\n",
    "train_major=train.filter(train.label_id==0).orderBy(rand())\n",
    "train_major=train_major.limit(5000)\n",
    "train=train.filter((train.label_id==1) | (train.label_id==2)).union(train_major)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert label to int type\n",
    "train = train.withColumn(\"label_id\", train[\"label_id\"].cast(IntegerType()))\n",
    "test = test.withColumn(\"label_id\", test[\"label_id\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa410fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns\n",
    "train=train.withColumnRenamed(\"free_text\",\"Comment\")\\\n",
    "    .withColumnRenamed(\"label_id\",\"Sentiment\")\n",
    "test=test.withColumnRenamed(\"free_text\",\"Comment\")\\\n",
    "    .withColumnRenamed(\"label_id\",\"Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc3df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data processing retains letters, spaces\n",
    "regex_pattern = \"[^a-zA-ZÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚĂĐĨŨƠàáâãèéêìíòóôõùúăđĩũơƯĂÂÊÔơưăâêô\\s]\"\n",
    "train = train.withColumn(\"Comment\", lower(regexp_replace(train[\"Comment\"], regex_pattern, \"\")))\n",
    "test = test.withColumn(\"Comment\", lower(regexp_replace(test[\"Comment\"], regex_pattern, \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92259ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null values \n",
    "train = train.na.drop(subset=[\"Comment\",\"Sentiment\"])\n",
    "test=train.na.drop(subset=[\"Comment\",\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.select(\"Sentiment\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd0d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the \"Comment\" column by splitting text based on whitespace\n",
    "tokenizer = RegexTokenizer(inputCol=\"Comment\", outputCol=\"words\", pattern=\"\\\\s+\")\n",
    "# Remove common stopwords from the tokenized words\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "# Convert words into numerical vectors using Word2Vec\n",
    "word2vec = Word2Vec(vectorSize=1000, minCount=3, inputCol=\"filtered_words\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ec514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics to evaluate Precision, Recall, F1 Score\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"Sentiment\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"Sentiment\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"Sentiment\", predictionCol=\"prediction\", metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c056131a",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a7486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline and training model random forest\n",
    "rf= RandomForestClassifier(featuresCol=\"features\",labelCol=\"Sentiment\")\n",
    "\n",
    "pipeline_rf = Pipeline(stages=[tokenizer, stopwords_remover, word2vec, rf])\n",
    "\n",
    "model_rf = pipeline_rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8dad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict in test dataset\n",
    "predictions_rf = model_rf.transform(test)\n",
    "predictions_rf.select(\"Sentiment\",\"prediction\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1c84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Precision: 0.6574, Recall: 0.8942, F1-score: 0.5681\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate model on test dataset\n",
    "precision_rf = precision_evaluator.evaluate(predictions_rf)\n",
    "recall_rf = recall_evaluator.evaluate(predictions_rf)\n",
    "f1_rf = f1_evaluator.evaluate(predictions_rf)\n",
    "\n",
    "print(f\"Random Forest - Precision: {precision_rf:.4f}, Recall: {recall_rf:.4f}, F1-score: {f1_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d03004",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc524cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 (Random Forest): 0.9237625958393878\n"
     ]
    }
   ],
   "source": [
    "# Optimize param with CrossValidation for RandomForest\n",
    "rf= RandomForestClassifier(featuresCol=\"features\",labelCol=\"Sentiment\")\n",
    "pipeline_rf = Pipeline(stages=[tokenizer, stopwords_remover, word2vec, rf])\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees, [50, 100, 150])  # Num tree\n",
    "             .addGrid(rf.maxDepth, [ 10, 15])  # Depth Tree\n",
    "             .build())\n",
    "\n",
    "# Cross Validator with 3 folds\n",
    "cv = CrossValidator(estimator=pipeline_rf,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=f1_evaluator,\n",
    "                    numFolds=3)  \n",
    "\n",
    "cvModel = cv.fit(train)\n",
    "\n",
    "predictions = cvModel.transform(test)\n",
    "\n",
    "f1 = f1_evaluator.evaluate(predictions)\n",
    "print(f\"f1 (Random Forest): {f1}\")\n",
    "\n",
    "best_model = cvModel.bestModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfb29b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select(\"Sentiment\",\"prediction\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8c0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best numTrees: 100\n",
      "Best maxDepth: 15\n"
     ]
    }
   ],
   "source": [
    "# Take best model Random Forest from CrossValidator\n",
    "best_rf_model = cvModel.bestModel.stages[-1]  # RandomForestClassifier last stage in pipeline\n",
    "\n",
    "# Show the param\n",
    "print(f\"Best numTrees: {best_rf_model.getNumTrees}\")\n",
    "print(f\"Best maxDepth: {best_rf_model.getMaxDepth()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3615d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf=best_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3191b74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Precision: 0.9155, Recall: 0.9790, F1-score: 0.9238\n"
     ]
    }
   ],
   "source": [
    "precision_rf = precision_evaluator.evaluate(predictions_rf)\n",
    "recall_rf = recall_evaluator.evaluate(predictions_rf)\n",
    "f1_rf = f1_evaluator.evaluate(predictions_rf)\n",
    "\n",
    "print(f\"Random Forest - Precision: {precision_rf:.4f}, Recall: {recall_rf:.4f}, F1-score: {f1_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d27b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "best_model.save(\"models/randomforest_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cb180f",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"Sentiment\", featuresCol=\"features\")\n",
    "pipeline_lr = Pipeline(stages=[tokenizer, stopwords_remover, word2vec, lr])\n",
    "\n",
    "\n",
    "model_lr = pipeline_lr.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr = model_lr.transform(test)\n",
    "predictions_lr.select(\"Sentiment\",\"prediction\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c05b323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Precision: 0.6570, Recall: 0.8904, F1-score: 0.5969\n"
     ]
    }
   ],
   "source": [
    "precision_lr = precision_evaluator.evaluate(predictions_lr)\n",
    "recall_lr = recall_evaluator.evaluate(predictions_lr)\n",
    "f1_lr = f1_evaluator.evaluate(predictions_lr)\n",
    "\n",
    "print(f\"Logistic Regression - Precision: {precision_lr:.4f}, Recall: {recall_lr:.4f}, F1-score: {f1_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5eee14",
   "metadata": {},
   "source": [
    "### Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc69020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 (Logistic Regression): 0.6101048121071495\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"Sentiment\", featuresCol=\"features\")\n",
    "pipeline_lr = Pipeline(stages=[tokenizer, stopwords_remover, word2vec, lr])\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.maxIter, [10, 50, 100])       # Iter\n",
    "             .addGrid(lr.regParam, [0.0, 0.1, 0.01])   #  regularization\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])  #  L1 & L2\n",
    "             .build())\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline_lr,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=f1_evaluator,\n",
    "                    numFolds=3)  \n",
    "\n",
    "cvModel = cv.fit(train)\n",
    "\n",
    "predictions = cvModel.transform(test)\n",
    "\n",
    "f1 = f1_evaluator.evaluate(predictions)\n",
    "print(f\"f1 (Logistic Regression): {f1}\")\n",
    "\n",
    "best_model_lr = cvModel.bestModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f060c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best maxIter: 100\n",
      "Best regParam: 0.0\n",
      "Best elasticNetParam: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Take best model Logistic Regression from CrossValidation\n",
    "best_lr_model = cvModel.bestModel.stages[-1] \n",
    "\n",
    "# Show optimize param\n",
    "print(f\"Best maxIter: {best_lr_model.getMaxIter()}\")\n",
    "print(f\"Best regParam: {best_lr_model.getRegParam()}\")\n",
    "print(f\"Best elasticNetParam: {best_lr_model.getElasticNetParam()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_lr.save(\"models/logisticRegression_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

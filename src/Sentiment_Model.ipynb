{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386b0790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import RandomForestClassifier,LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.sql.functions import lower, col,regexp_replace,rand\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, IntegerType\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, HashingTF, IDF,Word2Vec\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe8166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-DCB8O5U:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Sentiment-Model</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x24ad57b14d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 50954)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hongp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"C:\\Users\\hongp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"C:\\Users\\hongp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"C:\\Users\\hongp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"d:\\spark\\sparkenv\\Lib\\site-packages\\pyspark\\accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"d:\\spark\\sparkenv\\Lib\\site-packages\\pyspark\\accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"d:\\spark\\sparkenv\\Lib\\site-packages\\pyspark\\accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\spark\\sparkenv\\Lib\\site-packages\\pyspark\\serializers.py\", line 594, in read_int\n",
      "    length = stream.read(4)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hongp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os # chuyển os qua xài môi trường python myenv trùng với worker\n",
    "os.environ[\"PYTHONPATH\"] = \"C:/Users/hongp/OneDrive/Desktop/spark/sparkenv/Lib/site-packages\"\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "scala_version = '2.12'  # Scala version\n",
    "spark_version = '3.5.3' # Spark version\n",
    "\n",
    "packages = [\n",
    "    f'org.apache.spark:spark-sql-kafka-0-10_{scala_version}:{spark_version}',\n",
    "    'org.apache.kafka:kafka-clients:3.6.0'  # Kafka version\n",
    "]\n",
    "\n",
    "PYTHON_EXECUTABLE = \"C:/Users/hongp/OneDrive/Desktop/spark/sparkenv/Scripts/python.exe\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Sentiment-Model\") \\\n",
    "    .config(\"spark.jars.packages\", \",\".join(packages)) \\\n",
    "    .config(\"spark.pyspark.python\", PYTHON_EXECUTABLE) \\\n",
    "    .config(\"spark.pyspark.driver.python\", PYTHON_EXECUTABLE) \\\n",
    "    .config(\"spark.executorEnv.PYTHONPATH\", PYTHON_EXECUTABLE) \\\n",
    "    .config(\"spark.executorEnv.PYSPARK_PYTHON\", PYTHON_EXECUTABLE) \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"D:/spark-3.5.3-bin-hadoop3/spark-3.5.3-bin-hadoop3/jars\") \\\n",
    "    .config(\"spark.executor.extraClassPath\", \"D:/spark-3.5.3-bin-hadoop3/spark-3.5.3-bin-hadoop3/jars\") \\\n",
    "    .config(\"spark.local.dir\", \"C:/sparktmp\") \\\n",
    "    .config(\"spark.hadoop.io.native.lib\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2133c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|          Comment|\n",
      "+-----------------+\n",
      "|ngố vãi cả lồn|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "model_rf=PipelineModel.load(\"models/randomforest_model\")\n",
    "new_data = spark.createDataFrame([Row(Comment=\"ngố vãi cả lồn\")])\n",
    "new_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f08a73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\spark\\sparkenv\\Lib\\site-packages\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\hongp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\spark\\sparkenv\\Lib\\site-packages\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\spark\\sparkenv\\Lib\\site-packages\\py4j\\clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[WinError 10061] No connection could be made because the target machine actively refused it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_rf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mComment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\spark\\sparkenv\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:947\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prints the first ``n`` rows to the console.\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03mname | Bob\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\spark\\sparkenv\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:965\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[1;32m--> 965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\spark\\sparkenv\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[1;32md:\\spark\\sparkenv\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\spark\\sparkenv\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(10061, 'No connection could be made because the target machine actively refused it', None, 10061, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32md:\\spark\\sparkenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2181\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2178\u001b[0m         traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[0;32m   2179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2181\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_showtraceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_pdb:\n\u001b[0;32m   2183\u001b[0m     \u001b[38;5;66;03m# drop into debugger\u001b[39;00m\n\u001b[0;32m   2184\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebugger(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\spark\\sparkenv\\Lib\\site-packages\\ipykernel\\zmqshell.py:559\u001b[0m, in \u001b[0;36mZMQInteractiveShell._showtraceback\u001b[1;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[0;32m    553\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    554\u001b[0m sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    556\u001b[0m exc_content \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraceback\u001b[39m\u001b[38;5;124m\"\u001b[39m: stb,\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mename\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(etype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m),\n\u001b[1;32m--> 559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    560\u001b[0m }\n\u001b[0;32m    562\u001b[0m dh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayhook\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Send exception info over pub socket for other clients than the caller\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# to pick up\u001b[39;00m\n",
      "File \u001b[1;32md:\\spark\\sparkenv\\Lib\\site-packages\\py4j\\protocol.py:471\u001b[0m, in \u001b[0;36mPy4JJavaError.__str__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    470\u001b[0m     gateway_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_exception\u001b[38;5;241m.\u001b[39m_gateway_client\n\u001b[1;32m--> 471\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexception_cmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    472\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m get_return_value(answer, gateway_client, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;66;03m# Note: technically this should return a bytestring 'str' rather than\u001b[39;00m\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;66;03m# unicodes in Python 2; however, it can return unicodes for now.\u001b[39;00m\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;66;03m# See https://github.com/bartdag/py4j/issues/306 for more details.\u001b[39;00m\n",
      "File \u001b[1;32md:\\spark\\sparkenv\\Lib\\site-packages\\py4j\\java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[1;32md:\\spark\\sparkenv\\Lib\\site-packages\\py4j\\clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[1;32md:\\spark\\sparkenv\\Lib\\site-packages\\py4j\\clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[1;32md:\\spark\\sparkenv\\Lib\\site-packages\\py4j\\clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[1;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it"
     ]
    }
   ],
   "source": [
    "model_rf.transform(new_data).select(\"Comment\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efa8b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.read.csv(r\"D:\\spark\\vihsd\\train.csv\", header=True, inferSchema=True)\n",
    "test =spark.read.csv(r\"D:\\spark\\vihsd\\test.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2528d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|           free_text|label_id|\n",
      "+--------------------+--------+\n",
      "|Em được làm fan c...|       0|\n",
      "|Đúng là bọn mắt h...|       2|\n",
      "|Đậu Văn Cường giờ...|       0|\n",
      "|CÔN ĐỒ CỤC SÚC VÔ...|       2|\n",
      "|Từ lý thuyết đến ...|       0|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020012c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_major=train.filter(train.label_id==0).orderBy(rand())\n",
    "train_major=train_major.limit(5000)\n",
    "train=train.filter((train.label_id==1) | (train.label_id==2)).union(train_major)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd4c5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.withColumn(\"label_id\", train[\"label_id\"].cast(IntegerType()))\n",
    "test = test.withColumn(\"label_id\", test[\"label_id\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5177a036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- free_text: string (nullable = true)\n",
      " |-- label_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aa410fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.withColumnRenamed(\"free_text\",\"Comment\")\\\n",
    "    .withColumnRenamed(\"label_id\",\"Sentiment\")\n",
    "test=test.withColumnRenamed(\"free_text\",\"Comment\")\\\n",
    "    .withColumnRenamed(\"label_id\",\"Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cc3df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_pattern = \"[^a-zA-ZÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚĂĐĨŨƠàáâãèéêìíòóôõùúăđĩũơƯĂÂÊÔơưăâêô\\s]\"\n",
    "train = train.withColumn(\"Comment\", lower(regexp_replace(train[\"Comment\"], regex_pattern, \"\")))\n",
    "test = test.withColumn(\"Comment\", lower(regexp_replace(test[\"Comment\"], regex_pattern, \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92259ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.na.drop(subset=[\"Comment\",\"Sentiment\"])\n",
    "test=train.na.drop(subset=[\"Comment\",\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d2d8551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Sentiment|\n",
      "+---------+\n",
      "|        1|\n",
      "|        2|\n",
      "|        0|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.select(\"Sentiment\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd0d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer(inputCol=\"Comment\", outputCol=\"words\", pattern=\"\\\\s+\")\n",
    "\n",
    "stopwords_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "\n",
    "word2vec = Word2Vec(vectorSize=1000, minCount=3, inputCol=\"filtered_words\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "355ec514",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"Sentiment\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"Sentiment\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"Sentiment\", predictionCol=\"prediction\", metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c056131a",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a7486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf= RandomForestClassifier(featuresCol=\"features\",labelCol=\"Sentiment\")\n",
    "\n",
    "pipeline_rf = Pipeline(stages=[tokenizer, stopwords_remover, word2vec, rf])\n",
    "\n",
    "model_rf = pipeline_rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8dad0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|Sentiment|prediction|\n",
      "+---------+----------+\n",
      "|        2|       1.0|\n",
      "|        1|       0.0|\n",
      "|        1|       2.0|\n",
      "|        2|       2.0|\n",
      "|        0|       2.0|\n",
      "|        0|       0.0|\n",
      "|        1|       1.0|\n",
      "|        2|       0.0|\n",
      "|        0|       1.0|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions_rf = model_rf.transform(test)\n",
    "predictions_rf.select(\"Sentiment\",\"prediction\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1a1c84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Precision: 0.6574, Recall: 0.8942, F1-score: 0.5681\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Đánh giá mô hình\n",
    "precision_rf = precision_evaluator.evaluate(predictions_rf)\n",
    "recall_rf = recall_evaluator.evaluate(predictions_rf)\n",
    "f1_rf = f1_evaluator.evaluate(predictions_rf)\n",
    "\n",
    "print(f\"Random Forest - Precision: {precision_rf:.4f}, Recall: {recall_rf:.4f}, F1-score: {f1_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d03004",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccc524cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 (Random Forest): 0.9237625958393878\n"
     ]
    }
   ],
   "source": [
    "rf= RandomForestClassifier(featuresCol=\"features\",labelCol=\"Sentiment\")\n",
    "pipeline_rf = Pipeline(stages=[tokenizer, stopwords_remover, word2vec, rf])\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees, [50, 100, 150])  # Số cây \n",
    "             .addGrid(rf.maxDepth, [ 10, 15])  # Độ sâu của cây \n",
    "             .build())\n",
    "\n",
    "# Cross Validator với 3 folds\n",
    "cv = CrossValidator(estimator=pipeline_rf,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=f1_evaluator,\n",
    "                    numFolds=3)  \n",
    "\n",
    "cvModel = cv.fit(train)\n",
    "\n",
    "predictions = cvModel.transform(test)\n",
    "\n",
    "f1 = f1_evaluator.evaluate(predictions)\n",
    "print(f\"f1 (Random Forest): {f1}\")\n",
    "\n",
    "best_model = cvModel.bestModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cfb29b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|Sentiment|prediction|\n",
      "+---------+----------+\n",
      "|        2|       1.0|\n",
      "|        1|       0.0|\n",
      "|        1|       2.0|\n",
      "|        2|       2.0|\n",
      "|        0|       2.0|\n",
      "|        0|       0.0|\n",
      "|        1|       1.0|\n",
      "|        2|       0.0|\n",
      "|        0|       1.0|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"Sentiment\",\"prediction\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96d8c0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best numTrees: 100\n",
      "Best maxDepth: 15\n"
     ]
    }
   ],
   "source": [
    "# Lấy mô hình Random Forest tốt nhất từ CrossValidator\n",
    "best_rf_model = cvModel.bestModel.stages[-1]  # RandomForestClassifier là stage cuối cùng trong pipeline\n",
    "\n",
    "# In ra các tham số quan trọng\n",
    "print(f\"Best numTrees: {best_rf_model.getNumTrees}\")\n",
    "print(f\"Best maxDepth: {best_rf_model.getMaxDepth()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3615d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf=best_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3191b74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Precision: 0.9155, Recall: 0.9790, F1-score: 0.9238\n"
     ]
    }
   ],
   "source": [
    "precision_rf = precision_evaluator.evaluate(predictions_rf)\n",
    "recall_rf = recall_evaluator.evaluate(predictions_rf)\n",
    "f1_rf = f1_evaluator.evaluate(predictions_rf)\n",
    "\n",
    "print(f\"Random Forest - Precision: {precision_rf:.4f}, Recall: {recall_rf:.4f}, F1-score: {f1_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d27b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model.save(\"models/randomforest_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cb180f",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"Sentiment\", featuresCol=\"features\")\n",
    "pipeline_lr = Pipeline(stages=[tokenizer, stopwords_remover, word2vec, lr])\n",
    "\n",
    "\n",
    "model_lr = pipeline_lr.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a13cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|Sentiment|prediction|\n",
      "+---------+----------+\n",
      "|        2|       1.0|\n",
      "|        1|       0.0|\n",
      "|        1|       2.0|\n",
      "|        2|       2.0|\n",
      "|        0|       2.0|\n",
      "|        0|       0.0|\n",
      "|        1|       1.0|\n",
      "|        2|       0.0|\n",
      "|        0|       1.0|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_lr = model_lr.transform(test)\n",
    "predictions_lr.select(\"Sentiment\",\"prediction\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c05b323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Precision: 0.6570, Recall: 0.8904, F1-score: 0.5969\n"
     ]
    }
   ],
   "source": [
    "precision_lr = precision_evaluator.evaluate(predictions_lr)\n",
    "recall_lr = recall_evaluator.evaluate(predictions_lr)\n",
    "f1_lr = f1_evaluator.evaluate(predictions_lr)\n",
    "\n",
    "print(f\"Logistic Regression - Precision: {precision_lr:.4f}, Recall: {recall_lr:.4f}, F1-score: {f1_lr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd741277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "| Comment|\n",
      "+--------+\n",
      "|ghét vãi|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data = spark.createDataFrame([Row(Comment=\"ghét vãi\")])\n",
    "new_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53264c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "| Comment|prediction|\n",
      "+--------+----------+\n",
      "|ghét vãi|       1.0|\n",
      "+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lr.transform(new_data).select(\"Comment\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5eee14",
   "metadata": {},
   "source": [
    "### Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cc69020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 (Logistic Regression): 0.6101048121071495\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"Sentiment\", featuresCol=\"features\")\n",
    "pipeline_lr = Pipeline(stages=[tokenizer, stopwords_remover, word2vec, lr])\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.maxIter, [10, 50, 100])       # Tối ưu số vòng lặp\n",
    "             .addGrid(lr.regParam, [0.0, 0.1, 0.01])   # Tối ưu regularization\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])  # Điều chỉnh L1 & L2\n",
    "             .build())\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline_lr,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=f1_evaluator,\n",
    "                    numFolds=3)  \n",
    "\n",
    "cvModel = cv.fit(train)\n",
    "\n",
    "predictions = cvModel.transform(test)\n",
    "\n",
    "f1 = f1_evaluator.evaluate(predictions)\n",
    "print(f\"f1 (Logistic Regression): {f1}\")\n",
    "\n",
    "# In ra tham số tốt nhất\n",
    "best_model_lr = cvModel.bestModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1f060c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best maxIter: 100\n",
      "Best regParam: 0.0\n",
      "Best elasticNetParam: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Lấy mô hình Random Forest tốt nhất từ CrossValidator\n",
    "best_lr_model = cvModel.bestModel.stages[-1]  # RandomForestClassifier là stage cuối cùng trong pipeline\n",
    "\n",
    "# In ra các tham số quan trọng\n",
    "print(f\"Best maxIter: {best_lr_model.getMaxIter()}\")\n",
    "print(f\"Best regParam: {best_lr_model.getRegParam()}\")\n",
    "print(f\"Best elasticNetParam: {best_lr_model.getElasticNetParam()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_lr.save(\"models/logisticRegression_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
